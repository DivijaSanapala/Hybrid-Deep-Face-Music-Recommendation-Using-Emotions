import cv2
# Emotion Detection

pip install deepface
from deepface import DeepFace

# Input Image 
img = cv2.imread('happy_boy.jpg')

import numpy
import matplotlib.pyplot as plt
plt.imshow(img)

# To add Colour to the Image
plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))

# To predict the emotion of the person using DeepFace
predictions = DeepFace.analyze(img)
predictions
predictions['dominant_emotion']

# To Recognize the Face in the Image
faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
faces = faceCascade.detectMultiScale(gray,1.1,4)
for(x,y,w,h) in faces:
  cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0),2)
plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))

# To add the Emotion Recognized as text on Image
font = cv2.FONT_HERSHEY_SIMPLEX
cv2.putText(img, predictions['dominant_emotion'], (50,50),font,3,(0,255,0),2,cv2.LINE_4);
plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))

img = cv2.imread('sad_girl.jpg')
img = cv2.imread('angry_boy.jpg')

# Real Time Testing
from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode
def take_photo(filename='photo.jpg', quality=0.8):
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);
      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});
      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();
      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);
      // Wait for Capture to be clicked.
      await new Promise((resolve) => capture.onclick = resolve);
      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
  display(js)
  data = eval_js('takePhoto({})'.format(quality))
  binary = b64decode(data.split(',')[1])
  with open(filename, 'wb') as f:
    f.write(binary)
  return filename

from IPython.display import Image
try:
  filename = take_photo()
  print('Saved to {}'.format(filename))
  
  # Show the image which was just taken.
  display(Image(filename))
except Exception as err:
  # Errors will be thrown if the user does not have a webcam or if they do not
  # grant the page permission to access it.
  print(str(err))

im = cv2.imread('photo.jpg')
pred = DeepFace.analyze(im)
pred['dominant_emotion']
gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
faces = faceCascade.detectMultiScale(gray,1.1,4)
for(x,y,w,h) in faces:
  cv2.rectangle(im, (x,y), (x+w, y+h), (255,0,0),2)
font = cv2.FONT_HERSHEY_SIMPLEX
cv2.putText(im, pred['dominant_emotion'], (50,50),font,3,(0,255,0),2,cv2.LINE_4);
plt.imshow(cv2.cvtColor(im,cv2.COLOR_BGR2RGB))

# Music Recommendation

import pandas as pd

# Spotify Dataset for Songs
data=pd.read_csv('data.csv.zip',compression='zip')
data

# Using KMeans Clustering for Clusterings the Songs according to Emotions 
from sklearn.cluster import KMeans
from sklearn.utils import shuffle

data.drop_duplicates(inplace=True,subset=['name'])
name=data['name']
data['song_name']=name
data

cluster=data.groupby(by=data['kmeans'])
y=data.pop('kmeans')
x=data.drop(columns=['name','artists','id','release_date','song_name'])
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25)
!pip install lightgbm
from lightgbm import LGBMClassifier
model=LGBMClassifier().fit(x_train,y_train)
data

model.score(x_train,y_train)
model.score(x_test,y_test)

import lightgbm
import matplotlib.pyplot as plt
ax = lightgbm.plot_importance(model, max_num_features=10, figsize=(15,15))
plt.show()

df=cluster.apply(lambda x: x.sort_values(["popularity"],ascending=False))
df.reset_index(level=0, inplace=True)
from keras.preprocessing.image import img_to_array
import imutils
from keras.models import load_model
import numpy as np
import cv2
detection_model_path = 'haarcascade_frontalface_default.xml'
face_detection = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
EMOTIONS = ["happy","sad"]
face_detection = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

if predictions['dominant_emotion']=='sad' or predictions['dominant_emotion']=='angry' 
    or predictions['dominant_emotion']=='fear'or predictions['dominant_emotion']=='disgust':
    emotion_code=0
else:
    emotion_code=1

def get_results(emotion_code):
  NUM_RECOMMEND=10
  happy_set=[]
  sad_set=[]
  if emotion_code==1:
      happy_set.append(df[df['kmeans']==1]['song_name'].head(NUM_RECOMMEND))
      return pd.DataFrame(happy_set).T
  else:
      sad_set.append(df[df['kmeans']==0]['song_name'].head(NUM_RECOMMEND))
      return pd.DataFrame(sad_set).T

output_results = get_results(emotion_code)
print(output_results)
if emotion_code == 0:
    print('emotion detected is SAD')
else:
    print('emotion detected is HAPPY')

import random
search_query = "https://www.youtube.com/results?search_query="
if emotion_code == 1:
  #r1 = random.randint(0, 10)
  sname = "Mood"
  #sname = data.loc[19606].at["song_name"]
else:
  #r1 = random.randint(0, 10)
  sname = "Dakiti"
#sname = "Mood (feat. iann dior)"
#r1 = random.randint(0, 10)
#sname = data.loc[r1].at["song_name"]
#sname = df[df['kmeans']==0]['song_name']
print(sname)
#sname="Someone you love"
#sname = output_results[pd.DataFrame(happy_set).T]
s_name = sname.replace(" ", "+")
print(s_name)

# Youtube Link
html = urllib.request.urlopen(search_query+s_name)
video_ids = re.findall(r"watch\?v=(\S{11})", html.read().decode())
print(video_ids)

from IPython.display import YouTubeVideo
YouTubeVideo(video_ids[0])


